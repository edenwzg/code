{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#CHAPTER-8-Data-Wrangling:Join,Combine,and-Reshape\" data-toc-modified-id=\"CHAPTER-8-Data-Wrangling:Join,Combine,and-Reshape-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>CHAPTER 8 Data Wrangling:Join,Combine,and Reshape</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hierarchical-Indexing\" data-toc-modified-id=\"Hierarchical-Indexing-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Hierarchical Indexing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reordering-and-Sorting-Levels\" data-toc-modified-id=\"Reordering-and-Sorting-Levels-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Reordering and Sorting Levels</a></span></li><li><span><a href=\"#Summary-Statistics-by-Level\" data-toc-modified-id=\"Summary-Statistics-by-Level-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Summary Statistics by Level</a></span></li><li><span><a href=\"#Indexing-with-a-DataFrame's-columns\" data-toc-modified-id=\"Indexing-with-a-DataFrame's-columns-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Indexing with a DataFrame's columns</a></span></li></ul></li><li><span><a href=\"#Combining-and-Merging-Datasets\" data-toc-modified-id=\"Combining-and-Merging-Datasets-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Combining and Merging Datasets</a></span><ul class=\"toc-item\"><li><span><a href=\"#Database-Style-DataFrame-Joins\" data-toc-modified-id=\"Database-Style-DataFrame-Joins-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Database-Style DataFrame Joins</a></span></li><li><span><a href=\"#Merging-on-Index\" data-toc-modified-id=\"Merging-on-Index-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Merging on Index</a></span></li><li><span><a href=\"#Concatenating-Along-an-Axis\" data-toc-modified-id=\"Concatenating-Along-an-Axis-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Concatenating Along an Axis</a></span></li><li><span><a href=\"#Combining-Data-with-Overlap\" data-toc-modified-id=\"Combining-Data-with-Overlap-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>Combining Data with Overlap</a></span></li></ul></li><li><span><a href=\"#Reshaping-and-Pivoting\" data-toc-modified-id=\"Reshaping-and-Pivoting-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Reshaping and Pivoting</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reshaping-with-Hierarchical-Indexing\" data-toc-modified-id=\"Reshaping-with-Hierarchical-Indexing-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Reshaping with Hierarchical Indexing</a></span></li><li><span><a href=\"#Pivoting-“Long”-to-“Wide”-Format\" data-toc-modified-id=\"Pivoting-“Long”-to-“Wide”-Format-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Pivoting “Long” to “Wide” Format</a></span></li><li><span><a href=\"#Pivoting-“Wide”-to-“Long”-Format\" data-toc-modified-id=\"Pivoting-“Wide”-to-“Long”-Format-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Pivoting “Wide” to “Long” Format</a></span></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 8 Data Wrangling:Join,Combine,and Reshape\n",
    "<font color=Indigo>\n",
    "数据规整化：连接，合并和重塑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many applications, data may be spread across a number of files or databases or be arranged in a form that is not easy to analyze. This chapter focuses on tools to help combine, join, and rearrange data.\n",
    "<font color=Indigo>\n",
    "在许多应用程序中，数据可能分布在许多文件或数据库中，或者以不易分析的形式进行排列。本章重点介绍了帮助组合、连接和重新排列数据的工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I introduce the concept of hierarchical indexing in pandas, which is used extensively in some of these operations. I then dig into the particular data manipulations. You can see various applied usages of these tools in Chapter 14.\n",
    "<font color=Indigo>\n",
    "首先，我介绍了pandas的hierarchical indexing的概念，这在某些操作中被广泛使用。然后，我将深入研究特定的数据操作。在第14章中，您可以看到这些工具的各种应用用法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Indexing\n",
    "<font color=Indigo>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical indexing is an important feature of pandas that enables you to have multiple(two or more) index levels on an axis. Somewhat abstractly, it provides a way for you to work with higher dimensional data in a lower dimensional form. Let’s start with a simple example; create a Series with a list of lists (or arrays) as the index:\n",
    "<font color=Indigo>\n",
    "Hierarchical indexing是pandas的一个重要特性，它使您能够在一个轴上拥有多个(两个或多个)索引级别。抽象地说，它为您提供了一种以更高维度形式处理低维数据的方法。让我们从一个简单的例子开始;创建一个带有表中表(或数组)index的Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-52aa384d6aa9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m data = pd.Series(np.random.randn(9),\n\u001b[0m\u001b[0;32m      2\u001b[0m                 index=[['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'],\n\u001b[0;32m      3\u001b[0m                        [1, 2, 3, 1, 3, 1, 2, 2, 3]])\n\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.Series(np.random.randn(9),\n",
    "                index=[['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'],\n",
    "                       [1, 2, 3, 1, 3, 1, 2, 2, 3]])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you’re seeing is a prettified view of a Series with a `MultiIndex` as its index. The“gaps” in the index display mean “use the label directly above”:\n",
    "<font color=Indigo>\n",
    "你所看到的是一个美化视图，一个以MultiIndex为索引的Series。索引显示中的“缺口”意味着“直接使用上面的标签”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a hierarchically indexed object, so-called partial indexing is possible, enabling you to concisely select subsets of the data:\n",
    "<font color=Indigo>\n",
    "使用一个层次化的索引对象，可以使用所谓的局部索引，从而使您能够精确地选择数据的子集:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['b':'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[['b', 'd']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection is even possible from an “inner” level:\n",
    "<font color=Indigo>\n",
    "甚至可以从内部的级别来选择："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical indexing plays an important role in reshaping data and group-based operations like forming a pivot table. For example, you could rearrange the data into a DataFrame using its `unstack` method:\n",
    "<font color=Indigo>\n",
    "Hierarchical indexing在重构数据和基于组的操作方面扮演着重要的角色，像建立一个数据透视表这样的操作。例如，您可以使用DataFrame的`unstack`方法将其数据重新排列:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The inverse operation of `unstack` is `stack`:\n",
    "<font color=Indigo>\n",
    "`unstack`的反向操作是`stack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.unstack().stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`stack` and `unstack` will be explored in more detail later in this chapter.\n",
    "<font color=Indigo>\n",
    "`stack`和`unstack`将在本章后面更详细地探讨。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With a DataFrame, either axis can have a hierarchical index:\n",
    "<font color=Indigo>\n",
    "关于DataFrame，两个轴都可以有一个hierarchical index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.arange(12).reshape((4, 3)),\n",
    "                     index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]],\n",
    "                     columns=[['Ohio', 'Ohio', 'Colorado'],\n",
    "                              ['Green', 'Red', 'Green']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The hierarchical levels can have names (as strings or any Python objects). If so, these will show up in the console output:\n",
    "<font color=Indigo>\n",
    "分层级别可以拥有名称(字符串或任何Python对象)。这些名称将出现在控制台输出中:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame.index.names = ['key1', 'key2']\n",
    "frame.columns.names = ['state', 'color']\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Be careful to distinguish the index names 'state' and 'color' from the row labels.\n",
    "<font color=Indigo>\n",
    "要注意区分索引名称的“state”和“color”与行标签的差别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With partial column indexing you can similarly select groups of columns:\n",
    "<font color=Indigo>\n",
    "对于部分列索引，您可以用类似的方法选择一组列:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame['Ohio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A MultiIndex can be created by itself and then reused; the columns in the preceding DataFrame with level names could be created like this:\n",
    "<font color=Indigo>\n",
    "一个MultiIndex可以自己创建后再使用;前面的DataFrame中的列可以这样创建:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.MultiIndex.from_arrays([['Ohio', 'Ohio', 'Colorado'], ['Green', 'Red', 'Green']],\n",
    "                        names=['state', 'color'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reordering and Sorting Levels\n",
    "<font color=Indigo>\n",
    "重新排序和级别排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "At times you will need to rearrange the order of the levels on an axis or sort the data by the values in one specific level. The `swaplevel` takes two level numbers or names and returns a new object with the levels interchanged (but the data is otherwise unaltered):\n",
    "<font color=Indigo>\n",
    "有时，您需要重新排列某个轴上的level的顺序，或者根据某个特定level的值对数据进行排序。`swaplevel`接受两个level数字或level名称，并返回一个新对象，该对象的级别是相互交换的(但是数据是不改变的):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame.swaplevel('key1', 'key2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "sort_index, on the other hand, sorts the data using only the values in a single level. When swapping levels, it’s not uncommon to also use sort_index so that the result is lexicographically sorted by the indicated level:\n",
    "<font color=Indigo>\n",
    "另一方面，`sort_index`只使用单个level的值来对数据进行排序。在交换level时，使用`sort_index`是很常见的，因此结果是根据指定的`level`按照字母顺序排序的:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame.sort_index(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame.swaplevel(0, 1).sort_index(level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Data selection performance is much better on hierarchically indexed objects if the index is lexicographically sorted starting with the outermost level—that is, the result of calling sort_index(level=0) or sort_index().\n",
    "<font color=Indigo>\n",
    "如果索引是按照字母顺序排序从最外层开始排序的，那么数据选择的性能就会好得多，这是调用`sort_index(level=0)`或`sort_index()`的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Summary Statistics by Level\n",
    "<font color=Indigo>\n",
    "逐级汇总统计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Many descriptive and summary statistics on DataFrame and Series have a level option in which you can specify the level you want to aggregate by on a particular axis. Consider the above DataFrame; we can aggregate by level on either the rows or columns like so:\n",
    "<font color=Indigo>\n",
    "关于DataFrame和Series的许多描述性和汇总统计信息都有一个level的选项，在这个选项中，您可以指定想要在某个特定轴上指定聚合的level。考虑上述DataFrame;我们可以按照这样的行或列来聚合:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame.sum(level='key2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame.sum(level='color', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Under the hood, this utilizes pandas’s groupby machinery, which will be discussed in more detail later in the book.\n",
    "<font color=Indigo>\n",
    "高级选项，是利用pandas的groupby机制，这本书将在后面的章节中更详细地讨论。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Indexing with a DataFrame's columns\n",
    "<font color=Indigo>\n",
    "使用DataFrame的columns进行索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It’s not unusual to want to use one or more columns from a DataFrame as the row index; alternatively, you may wish to move the row index into the DataFrame’s columns. Here’s an example DataFrame:\n",
    "<font color=Indigo>\n",
    "想要从DataFrame中使用一个或多个列作为行索引是很常见的；或者，您可能希望将行索引移动到DataFrame的列中。这里有一个例子DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = pd.DataFrame({'a': range(7), \n",
    "                      'b': range(7, 0, -1),\n",
    "                      'c': ['one', 'one', 'one', 'two', 'two', 'two', 'two'],\n",
    "                      'd': [0, 1, 2, 0, 1, 2, 3]})\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "DataFrame’s set_index function will create a new DataFrame using one or more of its columns as the index:\n",
    "<font color=Indigo>\n",
    "DataFrame的set_index函数将使用一个或多个列作为索引:创建一个新的DataFrame。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame2 = frame.set_index(['c', 'd'])\n",
    "frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "By default the columns are removed from the DataFrame, though you can leave them in:\n",
    "<font color=Indigo>\n",
    "默认情况下，这些列从DataFrame中删除，尽管您可以将它们留在原地:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame.set_index(['c', 'd'], drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "reset_index, on the other hand, does the opposite of set_index; the hierarchical index levels are moved into the columns:\n",
    "<font color=Indigo>\n",
    "另一方面，reset_index与set_index是相反的;hierarchical index levels被移动到列中:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame2.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Combining and Merging Datasets\n",
    "<font color=Indigo>\n",
    "数据集的组合和合并"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Data contained in pandas objects can be combined together in a number of ways:\n",
    "<font color=Indigo>\n",
    "pandas对象中包含的数据可以通过多种方式组合在一起:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- pandas.merge connects rows in DataFrames based on one or more keys. This will be familiar to users of SQL or other relational databases, as it implements database join operations.\n",
    "- pandas.concat concatenates or “stacks” together objects along an axis.\n",
    "- The combine_first instance method enables splicing together overlapping data to fill in missing values in one object with values from another.\n",
    "<font color=Indigo>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=Indigo>\n",
    "- pandas.merge基于一个或多个键连接DataFrames中的行。这对于SQL或其他关系数据库的用户来说是很熟悉的，因为它实现了数据库连接操作。\n",
    "- pandas.concat沿着一个轴连接对象\n",
    "- combine_first实例方法支持将重叠数据拼接在一起，以在一个对象中填充另一个对象的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I will address each of these and give a number of examples. They’ll be utilized in examples throughout the rest of the book.\n",
    "<font color=Indigo>\n",
    "我将一一介绍其中的每一个，并给出一些例子。在本书的其余部分中，它们将被用到。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Database-Style DataFrame Joins\n",
    "<font color=Indigo>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Merge or join operations combine datasets by linking rows using one or more keys. These operations are central to relational databases (e.g., SQL-based). The merge function in pandas is the main entry point for using these algorithms on your data.\n",
    "<font color=Indigo>\n",
    "合并或连接操作通过使用一个或多个键链接行来组合数据集。这些操作是关系数据库的核心(例如，基于sql的)。pandas的merge功能是在你的数据上使用这些算法的主要切入点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let’s start with a simple example:\n",
    "<font color=Indigo>\n",
    "让我们从一个简单的例子开始:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
    "                    'data1': range(7)})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'key': ['a', 'b', 'd'],\n",
    "                    'data2': range(3)})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is an example of a many-to-one join; the data in df1 has multiple rows labeled a and b, whereas df2 has only one row for each value in the key column. Calling merge with these objects we obtain:\n",
    "<font color=Indigo>\n",
    "这是一个多对一连接的示例;df1中的数据有多个行，列标记为a和b，而df2在键列中的每个值只有一行。再这些对象上调用merge我们将得到:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note that I didn’t specify which column to join on. If that information is not specified, merge uses the overlapping column names as the keys. It’s a good practice to specify explicitly, though:\n",
    "<font color=Indigo>\n",
    "注意，我没有指定要join哪个列。如果没有指定该信息，merge将使用重叠的列名作为键。明确地指出是一种很好的做法:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If the column names are different in each object, you can specify them separately:\n",
    "<font color=Indigo>\n",
    "如果每个对象的列名不同，您可以分别指定它们:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'lkey': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
    "                    'data1': range(7)})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame({'rkey': ['a', 'b', 'd'],\n",
    "                    'data2': range(3)})\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df3, df4, left_on='lkey', right_on='rkey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You may notice that the 'c' and 'd' values and associated data are missing from the result. By default merge does an 'inner' join; the keys in the result are the intersection, or the common set found in both tables. Other possible options are 'left', 'right', and 'outer'. The outer join takes the union of the keys, combining the effect of applying both left and right joins:\n",
    "<font color=Indigo>\n",
    "您可能会注意到，结果中缺少值“c”和“d”以及相关数据。默认情况下，merge会执行“inner”连接；结果中的键是交集，或者是在两个表中找到的公共集合。其他可选项是“left”、“right”和“outer”。outer连接使用了键的并集，结合了左和右连接的效果:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "See Table 8-1 for a summary of the options for how.\n",
    "<font color=Indigo>\n",
    "参见表8-1，以了解如何选择设置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 8-1. Different join types with how argument\n",
    "\n",
    "Option|Behavior\n",
    ":-|:-\n",
    "'inner' | Use only the key combinations observed in both tables\n",
    "'left' | Use all key combinations found in the left table\n",
    "'right' | Use all key combinations found in the right table\n",
    "'outer' | Use all key combinations observed in both tables together\n",
    "-------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表 8-1. 不同的连接类型和参数\n",
    "\n",
    "Option|Behavior\n",
    ":-|:-\n",
    "'inner' | 只使用两个表中公共的键组合\n",
    "'left' | 使用左表中找到的所有键组合\n",
    "'right' | 使用右表中找到的所有键组合\n",
    "'outer' | 使用两个表中找到的所有关键组合\n",
    "-------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Many-to-many merges have well-defined, though not necessarily intuitive, behavior. Here’s an example:\n",
    "<font color=Indigo>\n",
    "多对多的合并有明确的定义，尽管不一定是直观的行为。这里有一个例子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'b'],\n",
    "                    'data1': range(6)})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'key': ['a', 'b', 'a', 'b', 'd'],\n",
    "                    'data2': range(5)})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on='key', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Many-to-many joins form the Cartesian product of the rows. Since there were three 'b' rows in the left DataFrame and two in the right one, there are six 'b' rows in the result. The join method only affects the distinct key values appearing in the result:\n",
    "<font color=Indigo>\n",
    "多对多连接构成了行的笛卡尔积。由于左DataFrame中有3个“b”行，而右侧有两个行，因此结果中有6个“b”行。join方法只影响在结果中出现的不同的键值:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To merge with multiple keys, pass a list of column names:\n",
    "<font color=Indigo>\n",
    "要合并多个键，可以通过一个列名称列表:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key1': ['foo', 'foo', 'bar'],\n",
    "                     'key2': ['one', 'two', 'one'],\n",
    "                     'lval': [1, 2, 3]})\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "right = pd.DataFrame({'key1': ['foo', 'foo', 'bar', 'bar'],\n",
    "                      'key2': ['one', 'one', 'one', 'two'],\n",
    "                      'rval': [4, 5, 6, 7]})\n",
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left, right, on=['key1', 'key2'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To determine which key combinations will appear in the result depending on the choice of merge method, think of the multiple keys as forming an array of tuples to be used as a single join key (even though it’s not actually implemented that way).\n",
    "<font color=Indigo>\n",
    "要确定在结果中会出现哪些关键组合，取决于合并方法的选择，可以将多个键看作是一个数组的元组，作为一个单独的连接键使用(尽管实际上并不是这样实现的)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When you’re joining columns-on-columns, the indexes on the passed DataFrame objects are discarded.__\n",
    "<font color=Indigo>\n",
    "当您合并列到列时，传递的DataFrame对象上的索引会被丢弃。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A last issue to consider in merge operations is the treatment of overlapping column names. While you can address the overlap manually (see the earlier section on renaming axis labels), merge has a suffixes option for specifying strings to append to overlapping names in the left and right DataFrame objects:\n",
    "<font color=Indigo>\n",
    "在合并操作中要考虑的最后一个问题是对重叠列名的处理。虽然您可以手动处理重叠部分(请参阅前面关于重命名axis标签的部分)，但是merge有一个suffixes选项，用于指定在左边和右边的DataFrame对象中附加到重叠字符串上的名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left, right, on='key1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left, right, on='key1', suffixes=('_left', '_right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "See Table 8-2 for an argument reference on merge. Joining using the DataFrame’s row index is the subject of the next section.\n",
    "<font color=Indigo>\n",
    "有关merge的参数引用，请参见表8-2。使用DataFrame的行索引是下一节的主题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 8-2. merge function arguments\n",
    "\n",
    "Argument|Description\n",
    ":-|:-\n",
    "left | DataFrame to be merged on the left side.\n",
    "right | DataFrame to be merged on the right side.\n",
    "how | One of 'inner', 'outer', 'left', or 'right'; defaults to 'inner'.\n",
    "on | Column names to join on. Must be found in both DataFrame objects. If not specified and no other join keys given, will use the intersection of the column names in left and right as the join keys.\n",
    "left_on | Columns in left DataFrame to use as join keys.\n",
    "right_on | Analogous to left_on for left DataFrame.\n",
    "left_index | Use row index in left as its join key (or keys, if a MultiIndex).\n",
    "right_index | Analogous to left_index.\n",
    "sort | Sort merged data lexicographically by join keys; True by default (disable to get better performance in some cases on large datasets).\n",
    "suffixes | Tuple of string values to append to column names in case of overlap; defaults to ('_x', '_y') (e.g., if 'data' in both DataFrame objects, would appear as 'data_x' and 'data_y' in result).\n",
    "copy | If False, avoid copying data into resulting data structure in some exceptional cases; by default always copies.\n",
    "indicator | Adds a special column `_merge` that indicates the source of each row; values will be 'left_only','right_only', or 'both' based on the origin of the joined data in each row.\n",
    "-------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 8-2. merge函数的参数\n",
    "\n",
    "实参数|描述\n",
    ":-|:-\n",
    "left | DataFrame 合并左边的值.\n",
    "right | DataFrame 合并右边的值.\n",
    "how | 'inner', 'outer', 'left', or 'right'；默认为 'inner'.\n",
    "on | 要加入的列名。必须在DataFrame对象中能够找到。如果没有指定该参数，也没有指定其他的连接键，那么将使用left和right的列名作为连接键。\n",
    "left_on | 将left Dataframe中的列作为join keys使用.\n",
    "right_on | 与left_on的DataFrame相似。\n",
    "left_index | 使用左边的行索引作为它的连接键(或者多索引的键)。\n",
    "right_index | 类似于left_index.\n",
    "sort | 通过连接键来对数据进行排序；默认为True(在大数据集的情况下可以获得更好的性能)。\n",
    "suffixes | 如果列名重叠，将元祖字符串附加到列名中;默认为(`_x`，`_y`)(例如，如果`data`列名在所有的DataFrame对象中，结果会显示为'data_x'和'data_y')。\n",
    "copy | 如果为False, 在某些特殊情况下避免将数据复制到结果的数据结构中; 默认总是复制.\n",
    "indicator | 添加一个特殊的列 `_merge` 标明每一行的数据源；基于每一行的连接数据源，其值包含 'left_only','right_only', 或 'both'三种。\n",
    "-------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Merging on Index\n",
    "<font color=Indigo>\n",
    "索引上的合并"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In some cases, the merge key(s) in a DataFrame will be found in its index. In this case, you can pass left_index=True or right_index=True (or both) to indicate that the index should be used as the merge key:\n",
    "<font color=Indigo>\n",
    "有时候，DataFrame中的连接键位于其索引中。在这种情况下，你可以传入left_index=True或right_index=True(或两个都传)以说明索引应该被用作连接键："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left1 = pd.DataFrame({'key': ['a', 'b', 'a', 'a', 'b', 'c'],\n",
    "                      'value': range(6)})\n",
    "left1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "right1 = pd.DataFrame({'group_val': [3.5, 7]}, index=['a', 'b'])\n",
    "right1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left1, right1, left_on='key', right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Since the default merge method is to intersect the join keys, you can instead form the union of them with an outer join:\n",
    "<font color=Indigo>\n",
    "由于默认的merge方法是求取连接键的交集，因此你可以通过outer join的方式得到他们的并集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left1, right1, left_on='key', right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With hierarchically indexed data, things are more complicated, as joining on index is implicitly a multiple-key merge:\n",
    "<font color=Indigo>\n",
    "对于层次化索引的数据，事情将变得更加复杂，因为加入索引是隐式的多键合并:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lefth = pd.DataFrame({'key1': ['Ohio', 'Ohio', 'Ohio',\n",
    "....: 'Nevada', 'Nevada'],\n",
    "....: 'key2': [2000, 2001, 2002, 2001, 2002],\n",
    "....: 'data': np.arange(5.)})\n",
    "lefth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "righth = pd.DataFrame(np.arange(12).reshape((6, 2)),\n",
    "....: index=[['Nevada', 'Nevada', 'Ohio', 'Ohio',\n",
    "....: 'Ohio', 'Ohio'],\n",
    "....: [2001, 2000, 2000, 2000, 2001, 2002]],\n",
    "....: columns=['event1', 'event2'])\n",
    "righth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, you have to indicate multiple columns to merge on as a list (note the handling of duplicate index values with how='outer'):\n",
    "<font color=Indigo>\n",
    "在这种情况下，你必须以列表的形式指明用作和并键的多个列（注意使用how='outer'对重复索引值的处理以）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(lefth, righth, left_on=['key1', 'key2'], right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(lefth,righth, left_on=['key1', 'key2'], right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the indexes of both sides of the merge is also possible:\n",
    "<font color=Indigo>\n",
    "同时使用合并双方的索引也没问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left2 = pd.DataFrame([[1., 2.], [3., 4.], [5., 6.]],\n",
    "....: index=['a', 'c', 'e'],\n",
    "....: columns=['Ohio', 'Nevada'])\n",
    "left2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "right2 = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [13, 14]],\n",
    "....: index=['b', 'c', 'd', 'e'],\n",
    "....: columns=['Missouri', 'Alabama'])\n",
    "right2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left2, right2, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame has a convenient join instance for merging by index. It can also be used to combine together many DataFrame objects having the same or similar indexes but non-overlapping columns. In the prior example, we could have written:\n",
    "<font color=Indigo>\n",
    "DataFrame还有一个join实例方法，它可以更为方便地实现按索引合并。它还可以用于合并多个带有相同或相似索引的DataFrame对象，而不管他们之间有没有重叠的列。在前面的例子中，我们可以编写:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left2.join(right2, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part for legacy reasons (i.e., much earlier versions of pandas), DataFrame’s join method performs a left join on the join keys, exactly preserving the left frame’s row index. It also supports joining the index of the passed DataFrame on one of the columns of the calling DataFrame:\n",
    "<font color=Indigo>\n",
    "由于一些历史原因(早期版本的pandas)，DataFrame的join方法是在连接键上执行左连接，完全保留了左侧框架的行索引。它还支持参数DataFrame的索引跟调用者DataFrame的某个列之间的连接:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left1.join(right1, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, for simple index-on-index merges, you can pass a list of DataFrames to join as an alternative to using the more general concat function described in the next section:\n",
    "<font color=Indigo>\n",
    "最后，对于简单的索引合并，你还可以向join传入一组DataFrames，后面我们会介绍更为通用的concat函数，它也能够实现此功能:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "another = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [16., 17.]],\n",
    "....: index=['a', 'c', 'e', 'f'],\n",
    "....: columns=['New York', 'Oregon'])\n",
    "another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left2.join([right2, another])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left2.join([right2, another], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Concatenating Along an Axis\n",
    "<font color=Indigo>\n",
    "轴向连接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Another kind of data combination operation is referred to interchangeably as concatenation, binding, or stacking. NumPy’s concatenate function can do this with NumPy arrays:\n",
    "<font color=Indigo>\n",
    "另一种数据合并运算也被称作连接（concatenation）、绑定（binding）或堆叠（stacking）。NumPy有一个用于合并原始NumPy数组的concatenation函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.arange(12).reshape((3, 4))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.concatenate([arr, arr], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In the context of pandas objects such as Series and DataFrame, having labeled axes enable you to further generalize array concatenation. In particular, you have a number of additional things to think about:\n",
    "<font color=Indigo>\n",
    "对于pandas对象（如Series和DataFrame），有了标记的轴，就可以进一步扩展数组连接，具体来说，你还需要考虑以下事项："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- If the objects are indexed differently on the other axes, should we combine the distinct elements in these axes or use only the shared values (the intersection)?\n",
    "- Do the concatenated chunks of data need to be identifiable in the resulting object?\n",
    "- Does the “concatenation axis” contain data that needs to be preserved? In many cases, the default integer labels in a DataFrame are best discarded during concatenation.\n",
    "\n",
    "<font color=Indigo>\n",
    "- 如果各对象在其他轴上的索引不同，那么我们应该将这些轴上的不同元素组合在一起，还是只使用共享值(交集)?\n",
    "- 是否需要在结果对象中标识连接的数据块?\n",
    "- “连接轴”包含需要保存的数据吗？在许多情况下，DataFrame中的默认整数标签在连接过程中最好被丢弃。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concat function in pandas provides a consistent way to address each of these concerns. I’ll give a number of examples to illustrate how it works. Suppose we have three Series with no index overlap:\n",
    "<font color=Indigo>\n",
    "pandas的concat函数提供了一种能够解决这些问题的可靠方式。我将给出一些例子来说明它是如何工作的。假设我们有三个没有重叠索引的Series。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = pd.Series([0, 1], index=['a', 'b'])\n",
    "s2 = pd.Series([2, 3, 4], index=['c', 'd', 'e'])\n",
    "s3 = pd.Series([5, 6], index=['f', 'g'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling concat with these objects in a list glues together the values and indexes:\n",
    "<font color=Indigo>\n",
    "对这些对象调用concat可以将值和索引堆叠在一起:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([s1, s2, s3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default concat works along axis=0, producing another Series. If you pass axis=1, the result will instead be a DataFrame (axis=1 is the columns):\n",
    "<font color=Indigo>\n",
    "默认情况下，concat是在axis=0上工作，最终产生一个新的Series。如果传入axis=1，结果将会变成一个DataFrame(axis=1是列):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([s1, s2, s3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case there is no overlap on the other axis, which as you can see is the sorted union (the 'outer' join) of the indexes. You can instead intersect them by passing join='inner':\n",
    "<font color=Indigo>\n",
    "在这种情况下，另一条轴上没有重叠，正如您看到的，索引的排序是并集(“外连接”)。你可以通过传入join='inner'来得到他们的交集相交。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s4 = pd.concat([s1 * 5, s3])\n",
    "s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([s1, s4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([s1, s4], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this last example, the 'f' and 'g' labels disappeared because of the join='inner' option.\n",
    "<font color=Indigo>\n",
    "在最后一个例子中，“f”和“g”标签消失了，因为使用了join='inner'选项。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even specify the axes to be used on the other axes with join_axes:\n",
    "<font color=Indigo>\n",
    "你甚至可以通过join_axes指定要在其他轴上使用的索引:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([s1, s4], axis=1, join_axes=[['a', 'c', 'b', 'e']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A potential issue is that the concatenated pieces are not identifiable in the result. Suppose instead you wanted to create a hierarchical index on the concatenation axis. To do this, use the keys argument:\n",
    "<font color=Indigo>\n",
    "不过有个潜在的问题，参与连接的片段在结果中区分不开。如果你想要在连接轴上创建一个层次化索引，请使用keys参数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([s1, s1, s3], keys=['one', 'two', 'three'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of combining Series along axis=1, the keys become the DataFrame column headers:\n",
    "<font color=Indigo>\n",
    "如果将Series沿着axis=1合并，则keys变成了DataFrame的column herders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([s1, s2, s3], axis=1, keys=['one', 'two', 'three'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same logic extends to DataFrame objects:\n",
    "<font color=Indigo>\n",
    "同样的逻辑扩展到DataFrame对象也是一样的:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(6).reshape(3, 2), index=['a', 'b', 'c'],\n",
    "....: columns=['one', 'two'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(5 + np.arange(4).reshape(2, 2), index=['a', 'c'],\n",
    "....: columns=['three', 'four'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=1, keys=['level1', 'level2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass a dict of objects instead of a list, the dict’s keys will be used for the keys option:\n",
    "<font color=Indigo>\n",
    "如果你传递的不是列表而是一个字典，则字典的keys就会被当作keys选项的值:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat({'level1': df1, 'level2': df2}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are additional arguments governing how the hierarchical index is created (see Table 8-3). For example, we can name the created axis levels with the names argument:\n",
    "<font color=Indigo>\n",
    "还有一些关于如何创建层次化索引的附加参数(参见表8-3)。例如，我们可以用names参数来命名所创建的axis级别:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=1, keys=['level1', 'level2'], names=['upper', 'lower'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A last consideration concerns DataFrames in which the row index does not contain any relevant data:\n",
    "<font color=Indigo>\n",
    "最后一个需要考虑的问题是，生成跟当前分析无关的DataFrame行索引（也就是说那些行索引是无意义的）:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.random.randn(3, 4), columns=['a', 'b', 'c', 'd'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(np.random.randn(2, 3), columns=['b', 'd', 'a'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, you can pass ignore_index=True:\n",
    "<font color=Indigo>\n",
    "在这个例子中，你可以传递ignore_index=True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 8-3. concat function arguments\n",
    "\n",
    "Argument|Description\n",
    ":-|:-\n",
    "objs | List or dict of pandas objects to be concatenated; this is the only required argument\n",
    "axis | Axis to concatenate along; defaults to 0 (along rows)\n",
    "join | Either 'inner' or 'outer' ('outer' by default); whether to intersection (inner) or union (outer) together indexes along the other axes\n",
    "join_axes | Specific indexes to use for the other n–1 axes instead of performing union/intersection logic\n",
    "keys | Values to associate with objects being concatenated, forming a hierarchical index along the concatenation axis; can either be a list or array of arbitrary values, an array of tuples, or a list  of arrays (if multiple-level arrays passed in levels)\n",
    "levels | Specific indexes to use as hierarchical index level or levels if keys passed\n",
    "names | Names for created hierarchical levels if keys and/or levels passed\n",
    "verify_integrity | Check new axis in concatenated object for duplicates and raise exception if so; by default (False) allows duplicates\n",
    "ignore_index | Do not preserve indexes along concatenation axis, instead producing a new range(total_length) index\n",
    "-------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表 8-3. concat function arguments\n",
    "\n",
    "参数|描述\n",
    ":-|:-\n",
    "objs | 参与连接的pandas对象的列表或字典。唯一必须的参数\n",
    "axis | 指明连接的轴向，默认为0\n",
    "join | \"inner\"、\"outer\"其中之一，默认为\"outer\"。指明其他轴向上的索引是按交集（inner）还是并集（outer）进行合并\n",
    "join_axes | 指明用于其他n-1条轴的索引，不执行并集、交集运算\n",
    "keys | 与连接对象有关的值，用于形成连接轴向上的层次化索引。可以是任意值的列表或数组、元祖数组、数组列表（如果将levels设置成多级数组的话）\n",
    "levels | 指定用作层次化索引各级别上的索引，如果设置了keys的话（就是外层级别的索引）\n",
    "names | 用于创建分层级别额名称，如果设置了keys和（或）levels的话\n",
    "verify_integrity | 检查结果对象新轴上的重复情况，如果发现则引发异常。默认（False）允许重复。\n",
    "ignore_index | 不保留连接轴上的索引，产生一组新索引range(total_length)\n",
    "-------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Data with Overlap\n",
    "<font color=Indigo>\n",
    "合并重叠数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another data combination situation that can’t be expressed as either a merge or concatenation operation. You may have two datasets whose indexes overlap in full or part. As a motivating example, consider NumPy’s where function, which performs the array-oriented equivalent of an if-else expression:\n",
    "<font color=Indigo>\n",
    "还有另一种数据组合的情况，不能用简单的合并（merge）或连接（concatenation）操作来表示。比如说，你可能有索引全部或部分重叠两个数据集。给这个例子增加一点启发性，我们使用NumPy的where函数，它用于表达一种矢量化的if-else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.Series([np.nan, 2.5, np.nan, 3.5, 4.5, np.nan],\n",
    ".....: index=['f', 'e', 'd', 'c', 'b', 'a'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = pd.Series(np.arange(len(a), dtype=np.float64),\n",
    ".....: index=['f', 'e', 'd', 'c', 'b', 'a'])\n",
    "b[-1] = np.nan\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.where(pd.isnull(a), b, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series has a combine_first method, which performs the equivalent of this operation along with pandas’s usual data alignment logic:\n",
    "<font color=Indigo>\n",
    "Series有一个combine_first方法，实现的也是一样的功能，而且会进行数据对其："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b[:-2].combine_first(a[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With DataFrames, combine_first does the same thing column by column, so you can think of it as\n",
    "“patching” missing data in the calling object with data from the object you pass:\n",
    "<font color=Indigo>\n",
    "对于DataFrame，combine_first自然也会在列上做同样的事情，因此你可以将其看作：用参数对象中的数据为调用者对象的缺失数据“打补丁”："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'a': [1., np.nan, 5., np.nan],\n",
    ".....: 'b': [np.nan, 2., np.nan, 6.],\n",
    ".....: 'c': range(2, 18, 4)})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'a': [5., 4., np.nan, 3., 7.],\n",
    ".....: 'b': [np.nan, 3., 4., 6., 8.]})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.combine_first(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping and Pivoting\n",
    "<font color=Indigo>\n",
    "重塑和轴向旋转"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of basic operations for rearranging tabular data. These are alternatingly referred to as reshape or pivot operations.\n",
    "<font color=Indigo>\n",
    "有许多用于重新排列表格形数据的基础运算。这些函数也称作重塑（reshape）或轴向旋转（pivot）运算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reshaping with Hierarchical Indexing\n",
    "<font color=Indigo>\n",
    "重塑层次化索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Hierarchical indexing provides a consistent way to rearrange data in a DataFrame.There are two primary actions:\n",
    "<font color=Indigo>\n",
    "层次化索引为DataFrame数据的重排任务提供了一种具有良好一致性的方式。主要功能有二："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- stack：This “rotates” or pivots from the columns in the data to the rows\n",
    "- unstack：This pivots from the rows into the columns\n",
    "\n",
    "<font color=Indigo>\n",
    "- stack：将数据的列“旋转”为行。\n",
    "- unstack：将数据的行“旋转”为列。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I’ll illustrate these operations through a series of examples. Consider a small DataFrame with string arrays as row and column indexes:\n",
    "<font color=Indigo>\n",
    "我将通过一系列范例来讲解这些操作。接下来看一个简单的DataFrame，其中的行列索引均为字符串："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(6).reshape((2, 3)),\n",
    "                   index=pd.Index(['Ohio', 'Colorado'], name='state'),\n",
    "                   columns=pd.Index(['one', 'two', 'three'],name='number'))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the stack method on this data pivots the columns into the rows, producing a Series:\n",
    "<font color=Indigo>\n",
    "使用该数据的stack方法即可将列转换为行，得到一个Series："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = data.stack()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a hierarchically indexed Series, you can rearrange the data back into a DataFrame with unstack:\n",
    "<font color=Indigo>\n",
    "对于一个层次化索引的Series，你可以用unstack将其重排为一个DataFrame："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the innermost level is unstacked (same with stack). You can unstack a different level by passing a level number or name:\n",
    "<font color=Indigo>\n",
    "默认情况下，unstack操作的是最内层（stack也是如此）。传入分层级别的标号或名称即可对其他级别进行unstack操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.unstack('state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unstacking might introduce missing data if all of the values in the level aren’t found in each of the subgroups:\n",
    "<font color=Indigo>\n",
    "如果不是所有的级别值都能在各分组中找到的话，则unstack操作可能会引入缺失数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s1 = pd.Series([0, 1, 2, 3], index=['a', 'b', 'c', 'd'])\n",
    "s2 = pd.Series([4, 5, 6], index=['c', 'd', 'e'])\n",
    "data2 = pd.concat([s1, s2], keys=['one', 'two'])\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data2.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking filters out missing data by default, so the operation is more easily invertible:\n",
    "<font color=Indigo>\n",
    "stack默认会过滤缺失数据，因此该运算是可逆的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2.unstack().stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2.unstack().stack(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you unstack in a DataFrame, the level unstacked becomes the lowest level in the result:\n",
    "<font color=Indigo>\n",
    "在对DataFrame进行unstack操作时，作为旋转轴的级别将会称为结果中最低级别的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'left': result, 'right': result + 5},\n",
    ".....: columns=pd.Index(['left', 'right'], name='side'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.unstack('state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When calling stack, we can indicate the name of the axis to stack:\n",
    "<font color=Indigo>\n",
    "当调用stack时，我们可以指示堆叠轴的名称:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.unstack('state').stack('side')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting “Long” to “Wide” Format\n",
    "<font color=Indigo>\n",
    "将“长格式”旋转为“宽格式”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common way to store multiple time series in databases and CSV is in so-called long or stacked format. Let’s load some example data and do a small amount of time series wrangling and other data cleaning:\n",
    "<font color=Indigo>\n",
    "在数据库和CSV中存储多个时间序列的常用方法是所谓的“长格式”或“堆叠格式”。让我们加载一些示例数据，并对少量时间序列进行规整和清理:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('d:/pydata-book/examples/macrodata.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "periods = pd.PeriodIndex(year=data.year, quarter=data.quarter, name='date')\n",
    "columns = pd.Index(['realgdp', 'infl', 'unemp'], name='item')\n",
    "data = data.reindex(columns=columns)\n",
    "data.index=periods.to_timestamp('D', 'end')\n",
    "ldata = data.stack().reset_index().rename(columns={0: 'value'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at PeriodIndex a bit more closely in Chapter 11. In short, it combines the year and quarter columns to create a kind of time interval type.\n",
    "<font color=Indigo>\n",
    "我们将在第11章更仔细地研究PeriodIndex。简而言之，它结合了year和quarter列，创建了一种时间间隔类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldata[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the so-called long format for multiple time series, or other observational data with two or more keys (here, our keys are date and item). Each row in the table represents a single observation.\n",
    "<font color=Indigo>\n",
    "这就是所谓的多时间序列的长格式，或者其他有两个或多个键的观察数据(这里，我们的键是date和item)。表中的每一行表示一个单独的观察数据行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is frequently stored this way in relational databases like MySQL, as a fixed schema (column names and data types) allows the number of distinct values in the item column to change as data is added to the table. In the previous example, date and item would usually be the primary keys (in relational database parlance), offering oth relational integrity and easier joins. In some cases, the data may be more difficult o work with in this format; you might prefer to have a DataFrame containing ne column per distinct item value indexed by timestamps in the date column. DataFrame’s pivot method performs exactly this transformation:\n",
    "<font color=Indigo>\n",
    "关系数据库（如MySQL）中的数据经常都是这样存储的，因为固定架构（即列名和数据类型）有一个好处：随着表中数据的添加或删除，item列中的值的种类能够增加或减少。在上面那个例子中，data和item通常都是主键（用关系型数据库的说法），不仅提供了关系完整性，而且提供了更为简单的查询支持。当然这也是有缺点的：长格式的数据操作起来可能不那么轻松。你可能会更喜欢DataFrame，不同的item值分别形成一列，date列中的事件值则用作索引。DataFrame的pivot方法完全可以实现这个转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pivoted = ldata.pivot('date', 'item', 'value')\n",
    "pivoted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The first two values passed are the columns to be used respectively as the row and column index, then finally an optional value column to fill the DataFrame. Suppose you had two value columns that you wanted to reshape simultaneously:\n",
    "<font color=Indigo>\n",
    "前两个参数值分别用作行和列索引的列名，最后一个值则是用于填充DataFrame的数据列的列名。假设有两个需要参与重塑的数据列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldata['value2'] = np.random.randn(len(ldata))\n",
    "ldata[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "By omitting the last argument, you obtain a DataFrame with hierarchical columns:\n",
    "<font color=Indigo>\n",
    "如果忽略最后一个参数，得到的DataFrame就会带有层次化的列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pivoted = ldata.pivot('date', 'item')\n",
    "pivoted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pivoted['value'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note that pivot is equivalent to creating a hierarchical index using set_index followed by a call to unstack:\n",
    "<font color=Indigo>\n",
    "注意，pivot其实只是一个快捷方式而已：用set_index创建层次化索引，再用unstack重塑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unstacked = ldata.set_index(['date', 'item']).unstack('item')\n",
    "unstacked[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Pivoting “Wide” to “Long” Format\n",
    "<font color=Indigo>\n",
    "将“宽格式”旋转为“长格式”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "An inverse operation to pivot for DataFrames is pandas.melt. Rather than transforming one column into many in a new DataFrame, it merges multiple columns into one, producing a DataFrame that is longer than the input. Let’s look at an example:\n",
    "<font color=Indigo>\n",
    "对DataFrames的反向操作是pandas.melt。它不是将一个列转换成一个新的DataFrame，而是将多个列合并为一个，生成一个比输入长得多的DataFrame。让我们来看一个例子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'key': ['foo', 'bar', 'baz'],\n",
    ".....: 'A': [1, 2, 3],\n",
    ".....: 'B': [4, 5, 6],\n",
    ".....: 'C': [7, 8, 9]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'key' column may be a group indicator, and the other columns are data values.When using pandas.melt, we must indicate which columns (if any) are group indicators. Let’s use 'key' as the only group indicator here:\n",
    "<font color=Indigo>\n",
    "“key”列可能是一个组指示器，而其他列是数据值。当使用pandas.melt，我们必须指出哪些列(如果有的话)是组指示器。让我们用'key'作为唯一的组指示器:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "melted = pd.melt(df, ['key'])\n",
    "melted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pivot, we can reshape back to the original layout:\n",
    "<font color=Indigo>\n",
    "使用pivot，我们可以重新回到原来的布局:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reshaped = melted.pivot('key', 'variable', 'value')\n",
    "reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the result of pivot creates an index from the column used as the row labels, we may want to use reset_index to move the data back into a column:\n",
    "<font color=Indigo>\n",
    "由于pivot的结果创建了作为行标签的列的索引，所以我们可能希望使用reset_index将数据移回一个列中:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reshaped.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify a subset of columns to use as value columns:\n",
    "<font color=Indigo>\n",
    "您还可以指定列的一个子集作为值列:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.melt(df, id_vars=['key'], value_vars=['A', 'B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.melt can be used without any group identifiers, too:\n",
    "<font color=Indigo>\n",
    "pandas.melt也可以在没有任何组标识符的情况下使用:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.melt(df, value_vars=['A', 'B', 'C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.melt(df, value_vars=['key', 'A', 'B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "<font color=Indigo>\n",
    "总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have some pandas basics for data import, cleaning, and reorganization under your belt, we are ready to move on to data visualization with matplotlib. We will return to pandas later in the book when we discuss more advanced analytics.\n",
    "<font color=Indigo>\n",
    "现在您已经有了一些pandas的基础知识，可以根据以往的经验进行数据导入、清理和重组，我们已经准备好转向使用matplotlib进行数据可视化了。稍后在本书的后面，当我们讨论更高级的数据分析时，我们将回到pandas中。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {
    "height": "1225px",
    "left": "0px",
    "right": "922px",
    "top": "106px",
    "width": "358px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
